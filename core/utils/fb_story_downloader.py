"""
Facebook Story Downloader - Fallback System
ÙŠØ³ØªØ®Ø¯Ù… Ù…ÙˆØ§Ù‚Ø¹ Ø®Ø§Ø±Ø¬ÙŠØ© ÙƒÙ€ fallback Ø¹Ù†Ø¯Ù…Ø§ ÙŠÙØ´Ù„ yt-dlp

Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©:
- FBDownloader
- SaveFrom
- SnapSave
"""

import requests
from bs4 import BeautifulSoup
import re
import logging
import json
from typing import Optional, Dict, Any
from urllib.parse import quote

logger = logging.getLogger(__name__)


class FBStoryDownloader:
    """Ù…Ø­Ù…Ù„ Facebook Stories Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙˆØ§Ù‚Ø¹ Ø®Ø§Ø±Ø¬ÙŠØ©"""

    # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©
    SERVICES = {
        'fbdownloader': {
            'name': 'FBDownloader',
            'api_url': 'https://fbdownloader.app/api/video',
            'method': 'post',
            'enabled': True
        },
        'savefrom': {
            'name': 'SaveFrom',
            'api_url': 'https://api.savefrom.net/info',
            'method': 'get',
            'enabled': True
        },
        'snapinsta': {
            'name': 'SnapInsta',
            'api_url': 'https://snapinsta.app/api/ajaxSearch',
            'method': 'post',
            'enabled': True
        }
    }

    @staticmethod
    def download_facebook_story(url: str) -> Dict[str, Any]:
        """
        ØªØ­Ù…ÙŠÙ„ Facebook Story Ù…Ù† Ù…ÙˆÙ‚Ø¹ Ø®Ø§Ø±Ø¬ÙŠ

        Args:
            url: Ø±Ø§Ø¨Ø· Facebook Story

        Returns:
            dict Ù…Ø¹ video_url Ùˆ info
        """

        logger.info(f"ğŸŒ [FB_STORY_DOWNLOADER] Attempting to download: {url[:80]}...")

        # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© 1: FBDownloader API
        result = FBStoryDownloader._try_fbdownloader(url)
        if result:
            logger.info("âœ… [FB_STORY_DOWNLOADER] Success via FBDownloader")
            return result

        # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© 2: SaveFrom
        result = FBStoryDownloader._try_savefrom(url)
        if result:
            logger.info("âœ… [FB_STORY_DOWNLOADER] Success via SaveFrom")
            return result

        # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© 3: Web Scraping Ù…Ø¨Ø§Ø´Ø±
        result = FBStoryDownloader._try_direct_scraping(url)
        if result:
            logger.info("âœ… [FB_STORY_DOWNLOADER] Success via Direct Scraping")
            return result

        logger.error("âŒ [FB_STORY_DOWNLOADER] All methods failed")
        return None

    @staticmethod
    def _try_fbdownloader(url: str) -> Optional[Dict[str, Any]]:
        """Ù…Ø­Ø§ÙˆÙ„Ø© Ø¹Ø¨Ø± FBDownloader"""
        try:
            logger.info("ğŸ”„ [FBDownloader] Trying FBDownloader API...")

            # FBDownloader API endpoint
            api_url = "https://www.fbdownloader.app/api/video"

            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Content-Type': 'application/json',
                'Accept': 'application/json',
            }

            payload = {
                'url': url
            }

            response = requests.post(
                api_url,
                json=payload,
                headers=headers,
                timeout=15
            )

            if response.status_code == 200:
                data = response.json()

                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ø§Ø¨Ø· Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
                if 'download' in data or 'url' in data or 'video' in data:
                    video_url = (
                        data.get('download') or
                        data.get('url') or
                        data.get('video', {}).get('url')
                    )

                    if video_url:
                        return {
                            'video_url': video_url,
                            'title': data.get('title', 'Facebook Story'),
                            'thumbnail': data.get('thumbnail'),
                            'source': 'FBDownloader'
                        }

            logger.warning(f"âš ï¸ [FBDownloader] Failed: {response.status_code}")

        except Exception as e:
            logger.error(f"âŒ [FBDownloader] Error: {e}")

        return None

    @staticmethod
    def _try_savefrom(url: str) -> Optional[Dict[str, Any]]:
        """Ù…Ø­Ø§ÙˆÙ„Ø© Ø¹Ø¨Ø± SaveFrom.net"""
        try:
            logger.info("ğŸ”„ [SaveFrom] Trying SaveFrom API...")

            # SaveFrom API
            api_url = f"https://api.savefrom.net/info?url={quote(url)}"

            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }

            response = requests.get(api_url, headers=headers, timeout=15)

            if response.status_code == 200:
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
                data = response.text

                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
                video_urls = re.findall(r'"url":"(https?://[^"]+)"', data)

                if video_urls:
                    return {
                        'video_url': video_urls[0],
                        'title': 'Facebook Story',
                        'source': 'SaveFrom'
                    }

            logger.warning(f"âš ï¸ [SaveFrom] Failed: {response.status_code}")

        except Exception as e:
            logger.error(f"âŒ [SaveFrom] Error: {e}")

        return None

    @staticmethod
    def _try_direct_scraping(url: str) -> Optional[Dict[str, Any]]:
        """Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† HTML"""
        try:
            logger.info("ğŸ”„ [Direct Scraping] Trying direct HTML extraction...")

            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5',
            }

            response = requests.get(url, headers=headers, timeout=15)

            if response.status_code == 200:
                html = response.text

                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙÙŠ HTML
                # Facebook ÙŠØ¶Ø¹ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙÙŠ meta tags Ø£Ùˆ JSON

                # Ù…Ø­Ø§ÙˆÙ„Ø© 1: og:video
                og_video = re.search(r'<meta property="og:video" content="([^"]+)"', html)
                if og_video:
                    video_url = og_video.group(1)
                    return {
                        'video_url': video_url,
                        'title': 'Facebook Story',
                        'source': 'Direct Scraping (og:video)'
                    }

                # Ù…Ø­Ø§ÙˆÙ„Ø© 2: JSON data
                json_match = re.search(r'<script[^>]*>.*?("video_url":\s*"([^"]+)")', html)
                if json_match:
                    video_url = json_match.group(2)
                    return {
                        'video_url': video_url,
                        'title': 'Facebook Story',
                        'source': 'Direct Scraping (JSON)'
                    }

            logger.warning(f"âš ï¸ [Direct Scraping] No video found in HTML")

        except Exception as e:
            logger.error(f"âŒ [Direct Scraping] Error: {e}")

        return None

    @staticmethod
    def download_file(video_url: str, output_path: str) -> bool:
        """
        ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø¨Ø§Ø´Ø±

        Args:
            video_url: Ø±Ø§Ø¨Ø· Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
            output_path: Ù…Ø³Ø§Ø± Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù

        Returns:
            True Ø¥Ø°Ø§ Ù†Ø¬Ø­ Ø§Ù„ØªØ­Ù…ÙŠÙ„
        """
        try:
            logger.info(f"ğŸ“¥ [Download] Downloading from: {video_url[:80]}...")

            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }

            response = requests.get(
                video_url,
                headers=headers,
                stream=True,
                timeout=30
            )

            if response.status_code == 200:
                with open(output_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)

                logger.info(f"âœ… [Download] Saved to: {output_path}")
                return True

            logger.error(f"âŒ [Download] Failed: HTTP {response.status_code}")

        except Exception as e:
            logger.error(f"âŒ [Download] Error: {e}")

        return False


# Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø³Ø±ÙŠØ¹Ø©
def download_facebook_story(url: str) -> Optional[Dict[str, Any]]:
    """
    Ø¯Ø§Ù„Ø© Ø³Ø±ÙŠØ¹Ø© Ù„ØªØ­Ù…ÙŠÙ„ Facebook Story

    Usage:
        result = download_facebook_story(url)
        if result:
            video_url = result['video_url']
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ...
    """
    return FBStoryDownloader.download_facebook_story(url)


def is_facebook_story(url: str) -> bool:
    """ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Facebook Story"""
    return '/stories/' in url.lower() and 'facebook.com' in url.lower()
